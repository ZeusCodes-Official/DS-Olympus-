# **Titanic - Machine Learning from Disaster **


**GOAL**

- It is your job to predict if a passenger survived the sinking of the Titanic or not.
- For each in the test set, you must predict a 0 or 1 value for the variable.


**DATASET**

Dataset can be downloaded from [here](https://www.kaggle.com/c/titanic/data).



**WHAT I HAD DONE**

- Importing Libraries
- Missing Value Analysis
- Outlier Detection
- Machine Learning Model


**MODELS USED**

-  Logistic Regression
-  SGDClassifier
-  Support Vector Classifier
-  Random Forest Classifier
-  KNN
-  AdaBoostClassifier
-  Decision Tree Classifier
-  GradientBoostingClassifier
-  VotingClassifier


**LIBRARIES NEEDED**

- numpy
- pandas
- seaborn
- matplotlib
- scipy.stats
- scikit-learn

**Accuracy of different models used**

By using Logistic Regression I got 
 ```python
    test accuracy score of  Logistic Regression =  0.8188755470766468
 ``` 

By using Random Forest Classifier I got 
 ```python
    test accuracy score of Random Forest =  0.8340807174887892
 ``` 
 
 By using Decision Tree Classifier I got 
 ```python
    test accuracy score of Decision Tree =  0.8071748878923767
 ``` 
 
  By using  Support Vector Classifier I got 
 ```python
    test accuracy score of Support Vector Classifier =  0.8116591928251121
 ``` 
 
  By using GradientBoostingClassifier  I got 
 ```python
    test accuracy score of GradientBoostingClassifier =  0.8430493273542601
 ``` 
 
  By using AdaBoostClassifier I got 
 ```python
    test accuracy score of  AdaBoostClassifier = 0.8251121076233184
 ``` 
 
  By using KNN I got 
 ```python
    test accuracy score of KNN =  0.8071748878923767
 ``` 
 
  By using VotingClassifier I got 
 ```python
    test accuracy score of VotingClassifier =  0.852
 ``` 
 
  By using SGDClassifier I got 
 ```python
    test accuracy score of SGDClassifier =  0.7847533632286996
 ``` 
 

